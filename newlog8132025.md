# Project Log: Hybrid Model Attempt & Compatibility Challenges

This log details the progress made since the last summary, focusing on our attempt to build a hybrid recommendation model and the technical hurdles encountered.

## 1. Decision to Build a Hybrid Model

Following the analysis of our pure collaborative filtering models (ALS and BPR), which showed limited performance due to data sparsity (especially the persistent zero median precision), we decided to pivot towards building a **Hybrid Recommendation System**. The goal was to leverage item metadata to improve recommendations, particularly for users with sparse interaction histories.

## 2. Locating and Loading Item Metadata

The first crucial step for a hybrid model was to incorporate item metadata.
- We confirmed that the Amazon dataset from Julian McAuley's lab typically includes such metadata.
- After some initial confusion regarding file paths and locations, we successfully identified `items.csv` as the metadata file.
- We then successfully loaded both `ratings.csv` and `items.csv` into pandas DataFrames, overcoming `FileNotFoundError` by correctly identifying their location within the `data/processed/amazon_all_beauty/` directory.

## 3. Preparing Data for LightFM

We chose the `LightFM` library for building our hybrid model due to its ability to seamlessly integrate item features.

### Step 2: Processing Item Features
- We began by extracting item features, specifically using the `store` (brand) column from `items.csv`.
- Initially, this step was very slow due to the use of `iterrows()` within a loop.
- We successfully **optimized this step** by replacing the loop with vectorized pandas operations, significantly speeding up the feature extraction process.

### Step 3: Building the LightFM Dataset
- We then attempted to build the `LightFM Dataset` object, which involves mapping raw user/item IDs and features to internal integer IDs and constructing sparse interaction and item feature matrices.
- This step proved to be very computationally intensive due to the large size of the dataset (over 600k ratings, 112k items). The process ran for over 90 minutes, consuming significant CPU resources.

## 4. LightFM Installation Challenges

During the attempt to build the LightFM Dataset, we encountered a `ModuleNotFoundError`, indicating `lightfm` was not installed.
- We attempted to install `lightfm` with CUDA support (`!pip install lightfm[cuda]`), but this failed with an `AttributeError: 'dict' object has no attribute '__LIGHTFM_SETUP__'`.
- We then tried installing the base `lightfm` (`!pip install lightfm`), but the **same `AttributeError` persisted**.

## 5. Conclusion: Python Version Incompatibility

The persistent `AttributeError` indicates a **known compatibility issue between LightFM (version 1.17) and Python 3.12**. LightFM's build process is not compatible with changes introduced in Python 3.12.

This means that to proceed with LightFM, the current Python environment is unsuitable. The solution requires:
- Creating a new virtual environment.
- Installing a compatible Python version (e.g., Python 3.11 or earlier) within that environment.
- Installing `lightfm` (and `ipykernel`) in the new environment.
- Configuring Jupyter to use the new kernel.

This compatibility hurdle marks a natural stopping point for the current session.